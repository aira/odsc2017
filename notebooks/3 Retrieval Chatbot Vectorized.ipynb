{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    .container {\n",
       "        width: 99%;\n",
       "    }   \n",
       "    div.cell{\n",
       "        width: 99%;\n",
       "        margin-left: 1%;\n",
       "        margin-right: auto;\n",
       "    }\n",
       "    div.cell.selected {\n",
       "        border-left-width: 1px;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Ground Truth Utterance</th>\n",
       "      <th>Distractor_0</th>\n",
       "      <th>Distractor_1</th>\n",
       "      <th>Distractor_2</th>\n",
       "      <th>Distractor_3</th>\n",
       "      <th>Distractor_4</th>\n",
       "      <th>Distractor_5</th>\n",
       "      <th>Distractor_6</th>\n",
       "      <th>Distractor_7</th>\n",
       "      <th>Distractor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anyone knows why my stock oneiric exports env ...</td>\n",
       "      <td>nice thanks! __eou__</td>\n",
       "      <td>wrong channel for it, but check efnet.org, uno...</td>\n",
       "      <td>every time the kernel changes, you will lose v...</td>\n",
       "      <td>ok __eou__</td>\n",
       "      <td>!nomodeset &gt; acer __eou__ I'm assuming it is a...</td>\n",
       "      <td>http://www.ubuntu.com/project/about-ubuntu/der...</td>\n",
       "      <td>thx __eou__ unfortunately the program isn't in...</td>\n",
       "      <td>how can I check? By doing a recovery for testi...</td>\n",
       "      <td>my humble apologies __eou__</td>\n",
       "      <td>#ubuntu-offtopic __eou__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i set up my hd such that i have to type a pass...</td>\n",
       "      <td>so you dont know, ok, anyone else? __eou__ you...</td>\n",
       "      <td>nmap is nice, but it wasn't what I was looking...</td>\n",
       "      <td>ok __eou__</td>\n",
       "      <td>cdrom worked fine on windows. __eou__ i dont ...</td>\n",
       "      <td>ah yes, i have read return as rerun __eou__</td>\n",
       "      <td>hm? __eou__</td>\n",
       "      <td>not the case, LTS is every other .04 release. ...</td>\n",
       "      <td>Pretty much __eou__</td>\n",
       "      <td>I used the one I downloaded from AMD __eou__</td>\n",
       "      <td>ffmpeg is part of the package , quixotedon , a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no suggestions? __eou__ links? __eou__ how can...</td>\n",
       "      <td>you cant load anything via usb or cd when luks...</td>\n",
       "      <td>-p  sorry... __eou__  nmap -p22 __eou__ It d...</td>\n",
       "      <td>i guess so i can't even launch it. __eou__</td>\n",
       "      <td>noted __eou__</td>\n",
       "      <td>rxvt-unicode is one __eou__</td>\n",
       "      <td>I tarred all of ~ __eou__</td>\n",
       "      <td>I tarred all of ~ __eou__</td>\n",
       "      <td>I don't really know if I can help, but I was c...</td>\n",
       "      <td>that works just fine, thanks! __eou__</td>\n",
       "      <td>thank you __eou__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I just added a second usb printer but not sure...</td>\n",
       "      <td>i was setting it up under the printer configur...</td>\n",
       "      <td>i'd say the most commonly venue would be via L...</td>\n",
       "      <td>the old hardy man page, http://manpages.ubuntu...</td>\n",
       "      <td>i'll give a try __eou__</td>\n",
       "      <td>by the way, the url you posted for davfs is fr...</td>\n",
       "      <td>http://ubuntuforums.org/showthread.php?t=15498...</td>\n",
       "      <td>So I load up putty gui, then what do I do? __e...</td>\n",
       "      <td>you should read error messages, it says 'are ...</td>\n",
       "      <td>waiting the college semester to close just to ...</td>\n",
       "      <td>I was calling myself a jerk. All I know is tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Context  \\\n",
       "0   anyone knows why my stock oneiric exports env ...   \n",
       "1   i set up my hd such that i have to type a pass...   \n",
       "..                                                ...   \n",
       "3   no suggestions? __eou__ links? __eou__ how can...   \n",
       "4   I just added a second usb printer but not sure...   \n",
       "\n",
       "                               Ground Truth Utterance  \\\n",
       "0                                nice thanks! __eou__   \n",
       "1   so you dont know, ok, anyone else? __eou__ you...   \n",
       "..                                                ...   \n",
       "3   you cant load anything via usb or cd when luks...   \n",
       "4   i was setting it up under the printer configur...   \n",
       "\n",
       "                                         Distractor_0  \\\n",
       "0   wrong channel for it, but check efnet.org, uno...   \n",
       "1   nmap is nice, but it wasn't what I was looking...   \n",
       "..                                                ...   \n",
       "3     -p  sorry... __eou__  nmap -p22 __eou__ It d...   \n",
       "4   i'd say the most commonly venue would be via L...   \n",
       "\n",
       "                                         Distractor_1  \\\n",
       "0   every time the kernel changes, you will lose v...   \n",
       "1                                          ok __eou__   \n",
       "..                                                ...   \n",
       "3          i guess so i can't even launch it. __eou__   \n",
       "4   the old hardy man page, http://manpages.ubuntu...   \n",
       "\n",
       "                                         Distractor_2  \\\n",
       "0                                          ok __eou__   \n",
       "1    cdrom worked fine on windows. __eou__ i dont ...   \n",
       "..                                                ...   \n",
       "3                                       noted __eou__   \n",
       "4                             i'll give a try __eou__   \n",
       "\n",
       "                                         Distractor_3  \\\n",
       "0   !nomodeset > acer __eou__ I'm assuming it is a...   \n",
       "1         ah yes, i have read return as rerun __eou__   \n",
       "..                                                ...   \n",
       "3                         rxvt-unicode is one __eou__   \n",
       "4   by the way, the url you posted for davfs is fr...   \n",
       "\n",
       "                                         Distractor_4  \\\n",
       "0   http://www.ubuntu.com/project/about-ubuntu/der...   \n",
       "1                                         hm? __eou__   \n",
       "..                                                ...   \n",
       "3                           I tarred all of ~ __eou__   \n",
       "4   http://ubuntuforums.org/showthread.php?t=15498...   \n",
       "\n",
       "                                         Distractor_5  \\\n",
       "0   thx __eou__ unfortunately the program isn't in...   \n",
       "1   not the case, LTS is every other .04 release. ...   \n",
       "..                                                ...   \n",
       "3                           I tarred all of ~ __eou__   \n",
       "4   So I load up putty gui, then what do I do? __e...   \n",
       "\n",
       "                                         Distractor_6  \\\n",
       "0   how can I check? By doing a recovery for testi...   \n",
       "1                                 Pretty much __eou__   \n",
       "..                                                ...   \n",
       "3   I don't really know if I can help, but I was c...   \n",
       "4    you should read error messages, it says 'are ...   \n",
       "\n",
       "                                         Distractor_7  \\\n",
       "0                         my humble apologies __eou__   \n",
       "1        I used the one I downloaded from AMD __eou__   \n",
       "..                                                ...   \n",
       "3               that works just fine, thanks! __eou__   \n",
       "4   waiting the college semester to close just to ...   \n",
       "\n",
       "                                         Distractor_8  \n",
       "0                            #ubuntu-offtopic __eou__  \n",
       "1   ffmpeg is part of the package , quixotedon , a...  \n",
       "..                                                ...  \n",
       "3                                   thank you __eou__  \n",
       "4   I was calling myself a jerk. All I know is tha...  \n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "np = pd.np\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import seaborn as sns\n",
    "from seaborn.utils import plt\n",
    "\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(open(\"../shared-resources/jupyter.css\", \"r\").read()))\n",
    "%matplotlib inline\n",
    "# import mpld3\n",
    "\n",
    "sns.mpl.rc(\"figure\", figsize=(16, 6))\n",
    "# plt.style.use('seaborn')\n",
    "# plt.rc(\"figure\", figsize=(16, 6))\n",
    "# mpld3.enable_notebook()\n",
    "\n",
    "\n",
    "from nlpia.data.loaders import get_data\n",
    "\n",
    "df = pd.read_csv('../shared-resources/chatbot/testset.csv', index_col=None, header=0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = tfidf.fit_transform(['elephant hello world', 'elephant another time'])\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.        ,  0.44943642,  0.6316672 ,  0.        ,  0.6316672 ],\n",
       "        [ 0.6316672 ,  0.44943642,  0.        ,  0.6316672 ,  0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = vectors.todense()\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'another': 0, 'elephant': 1, 'hello': 2, 'time': 3, 'world': 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.3, max_features=100000, min_df=8,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=8, max_df=.3, max_features=100000)\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.3, max_features=100000, min_df=8,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(pd.concat([df[df.columns[i]] for i in range(11)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anyone', 'knows', 'why', 'my', 'stock', 'oneiric', 'exports', 'env', 'var', 'username']\n",
      "12358\n"
     ]
    }
   ],
   "source": [
    "print(list(tfidf.vocabulary_)[:10])\n",
    "print(len(tfidf.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18920, 12358)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tfidf.transform(df.Context)\n",
    "X = X.todense()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18920, 12358)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tfidf.transform(df['Ground Truth Utterance']).todense()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm(x):\n",
    "    \"\"\" 2-norm of a vector \n",
    "    >>> x = np.random.randn(10)\n",
    "    >>> norm(x) == np.linalg.norm(x)\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum(x ** 2))\n",
    "\n",
    "x = np.random.rand(10)\n",
    "abs(norm(x) - np.linalg.norm(x)) / np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12358, 12358)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-692dc608a06e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X2' is not defined"
     ]
    }
   ],
   "source": [
    "dots = np.dot(X.T, X).T\n",
    "print(dots.shape)\n",
    "print(X2.shape)\n",
    "X2[:3], X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statement(s='Hi'):\n",
    "    q = np.array(tfidf.transform([s]).todense()[0])\n",
    "    q = q / norm(q)\n",
    "    dots = np.dot(q, X.T).T\n",
    "    best_i = 0\n",
    "    best_similarity = -1\n",
    "    for i, similarity in enumerate(dots):\n",
    "        # print(i, q, v)\n",
    "        if similarity > best_similarity:\n",
    "            best_similarity = similarity\n",
    "            best_i = i\n",
    "    return df.Context.iloc[best_i], best_i, best_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hello __eou__ __eot__ hello, can i help you? __eou__ __eot__ ',\n",
       " 1022,\n",
       " matrix([[ 0.71722115]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_statement('Hello Ubuntu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exactly my idea! __eou__'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Ground Truth Utterance'].iloc[get_statement(\"Ubuntu doesn't work on my Macbook Pro!\")[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply(s='Hi'):\n",
    "    return df['Ground Truth Utterance'].iloc[get_statement(s)[1]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nice thanks! __eou__'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reply('anyone knows why my stock oneiric exports env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'so you dont know, ok, anyone else? __eou__ you are like, yah my mouse doesnt work, reinstall your os lolol what a joke __eou__'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reply('i set up my hd such that i have to type a pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=500)\n",
    "pca = pca.fit(tfidf.transform(df.Context).todense())\n",
    "X_100d = pca.transform(X)\n",
    "y_100d = pca.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statement_100d(s='Hi'):\n",
    "    q = pca.transform(tfidf.transform([s]).todense())[0] / norm(q)\n",
    "    q = q / norm(q)\n",
    "    dots = np.dot(q, X.T).T\n",
    "    best_i = 0\n",
    "    best_similarity = -1\n",
    "    for i, similarity in enumerate(dots):\n",
    "        # print(i, q, v)\n",
    "        if similarity > best_similarity:\n",
    "            best_similarity = similarity\n",
    "            best_i = i\n",
    "    \n",
    "    return df.Context.iloc[best_i], best_i\n",
    "\n",
    "def get_reply_100d(s='Hi'):\n",
    "    return df['Ground Truth Utterance'].iloc[get_statement_100d(s)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anyone knows why my stock oneiric exports env var 'USERNAME'?  I mean what is that used for?  I know of $USER but not $USERNAME .  My precise install doesn't export USERNAME __eou__ __eot__ looks like it used to be exported by lightdm, but the line had the comment \"// FIXME: Is this required?\" so I guess it isn't surprising it is gone __eou__ __eot__ thanks!  How the heck did you figure that out? __eou__ __eot__ https://bugs.launchpad.net/lightdm/+bug/864109/comments/3 __eou__ __eot__ \n",
      "n\n",
      "ok, i just figured i'd ask here incase I was just retarded lol __eou__\n"
     ]
    }
   ],
   "source": [
    "print(get_statement_100d(df.Context[0])[0])\n",
    "print(get_reply_100d(df.Context[0])[0])\n",
    "print(get_reply_100d(\"I'm trying to use ubuntu on my macbook pro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I use cinnamon __eou__ But i don't know :P __eou__ __eot__ fair enough. I know Kazam has big issues in Gnome3 and cinnamon. __eou__ __eot__ \",\n",
       " 10644)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_statement_100d(\"me just installed another serial port copier but don't know\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('obi Its not working without USB stick. Without USB stick it asks to select a boot medium. With USB stick, it boots correctly. __eou__ obi Still the fdisk shows its not bootable. __eou__ __eot__ That display is irrelevant since 15 years :) __eou__ __eot__ ',\n",
       " 7989)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_statement_100d(\"I just added a second usb printer but not sure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and it still doesn't work? __eou__\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(get_reply_100d(\"Did you like the movie Avatar?\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
