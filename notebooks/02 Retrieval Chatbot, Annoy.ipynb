{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ODSC 2017 Slides \n",
    "\n",
    "* [Training a Prosocial Chatbot](https://docs.google.com/presentation/d/1IND6PXOxgYb2IVmXnaSoNBcIOaiUVU-iZ6vnYz6J6-E/edit?usp=sharing)\n",
    "* [Exploring Hyperspace](https://docs.google.com/presentation/d/1SEU8VL0KWPDKKZnBSaMxUBDDwI8yqIxu9RQtq2bpnNg/edit?usp=sharing)\n",
    "\n",
    "## Ubuntu Dialog Corpus\n",
    "\n",
    "* Ubuntu IRC channel (for developers and contributors)\n",
    "* ~1.5 M Dialogs (interactions)\n",
    "* ~10 M Utterances (statements)\n",
    "\n",
    "## Application\n",
    "\n",
    "[![Aira, a visual interpreter for the blind](../data/aira_video_demo_blind_person_512.png)](https://vimeo.com/143070863)\n",
    "\n",
    "### References\n",
    "\n",
    "* [Aira](http://aira.io), A Visual Interpreter for the Blind\n",
    "* [WildML](http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/)\n",
    "* 2018, Lane, Howard and Hapke: [Natural Language Processing in Action](https://www.manning.com/books/natural-language-processing-in-action/?a_aid=totalgood)\n",
    "* 2016, Lowe, et al: [\"The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems\"](https://arxiv.org/pdf/1506.08909.pdf)\n",
    "* [training set generator v1](https://github.com/rkadlec/ubuntu-ranking-dataset-creator)\n",
    "* Lowe, [training set generator v2](https://github.com/ryan-lowe/Ubuntu-Dialogue-Generationv2)\n",
    "* Shmalko, [lexica and slang normalizers](https://github.com/rasendubi/noisy-text/tree/master/data\n",
    "* [retrieval-based vs rule-based and new modular approach](http://www.aclweb.org/old_anthology/C/C14/C14-1088.pdf)\n",
    "* [retrieval-based bot](https://export.arxiv.org/pdf/1612.01627)\n",
    "* [wrong idea about retrieval-bots](https://icrunchdata.com/blog/587/state-of-innovative-chatbots-and-intuitive-ai-in-2017/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV with `read_csv(*('../data/ubuntu_dialog_test_10.csv',), **{'low_memory': False})`...\n",
      "(18920, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nlpia.data.loaders import read_csv\n",
    "\n",
    "df = read_csv('../data/ubuntu_dialog_test_10.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Ground Truth Utterance</th>\n",
       "      <th>Distractor_0</th>\n",
       "      <th>Distractor_1</th>\n",
       "      <th>Distractor_2</th>\n",
       "      <th>Distractor_3</th>\n",
       "      <th>Distractor_4</th>\n",
       "      <th>Distractor_5</th>\n",
       "      <th>Distractor_6</th>\n",
       "      <th>Distractor_7</th>\n",
       "      <th>Distractor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anyone knows why my stock oneiric exports env ...</td>\n",
       "      <td>nice thanks! __eou__</td>\n",
       "      <td>wrong channel for it, but check efnet.org, uno...</td>\n",
       "      <td>every time the kernel changes, you will lose v...</td>\n",
       "      <td>ok __eou__</td>\n",
       "      <td>!nomodeset &gt; acer __eou__ I'm assuming it is a...</td>\n",
       "      <td>http://www.ubuntu.com/project/about-ubuntu/der...</td>\n",
       "      <td>thx __eou__ unfortunately the program isn't in...</td>\n",
       "      <td>how can I check? By doing a recovery for testi...</td>\n",
       "      <td>my humble apologies __eou__</td>\n",
       "      <td>#ubuntu-offtopic __eou__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i set up my hd such that i have to type a pass...</td>\n",
       "      <td>so you dont know, ok, anyone else? __eou__ you...</td>\n",
       "      <td>nmap is nice, but it wasn't what I was looking...</td>\n",
       "      <td>ok __eou__</td>\n",
       "      <td>cdrom worked fine on windows. __eou__ i dont ...</td>\n",
       "      <td>ah yes, i have read return as rerun __eou__</td>\n",
       "      <td>hm? __eou__</td>\n",
       "      <td>not the case, LTS is every other .04 release. ...</td>\n",
       "      <td>Pretty much __eou__</td>\n",
       "      <td>I used the one I downloaded from AMD __eou__</td>\n",
       "      <td>ffmpeg is part of the package , quixotedon , a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im trying to use ubuntu on my macbook pro reti...</td>\n",
       "      <td>just wondering how it runs __eou__</td>\n",
       "      <td>yes, that's what I did, exported it to a \"id_d...</td>\n",
       "      <td>nothing - i am talking about the question of m...</td>\n",
       "      <td>that should fix the fonts being too large __eou__</td>\n",
       "      <td>okay, so hcitool echos back hci0 &lt;mac address ...</td>\n",
       "      <td>I get to the menu with options such as 'try ub...</td>\n",
       "      <td>why do u need analyzer __eou__ it is a toy __e...</td>\n",
       "      <td>Cntrl-C may stop the command but it doesn't fi...</td>\n",
       "      <td>if you're only going to run Ubuntu, just get a...</td>\n",
       "      <td>the ones which are not picked up at the moment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no suggestions? __eou__ links? __eou__ how can...</td>\n",
       "      <td>you cant load anything via usb or cd when luks...</td>\n",
       "      <td>-p  sorry... __eou__  nmap -p22 __eou__ It d...</td>\n",
       "      <td>i guess so i can't even launch it. __eou__</td>\n",
       "      <td>noted __eou__</td>\n",
       "      <td>rxvt-unicode is one __eou__</td>\n",
       "      <td>I tarred all of ~ __eou__</td>\n",
       "      <td>I tarred all of ~ __eou__</td>\n",
       "      <td>I don't really know if I can help, but I was c...</td>\n",
       "      <td>that works just fine, thanks! __eou__</td>\n",
       "      <td>thank you __eou__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I just added a second usb printer but not sure...</td>\n",
       "      <td>i was setting it up under the printer configur...</td>\n",
       "      <td>i'd say the most commonly venue would be via L...</td>\n",
       "      <td>the old hardy man page, http://manpages.ubuntu...</td>\n",
       "      <td>i'll give a try __eou__</td>\n",
       "      <td>by the way, the url you posted for davfs is fr...</td>\n",
       "      <td>http://ubuntuforums.org/showthread.php?t=15498...</td>\n",
       "      <td>So I load up putty gui, then what do I do? __e...</td>\n",
       "      <td>you should read error messages, it says 'are ...</td>\n",
       "      <td>waiting the college semester to close just to ...</td>\n",
       "      <td>I was calling myself a jerk. All I know is tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  anyone knows why my stock oneiric exports env ...   \n",
       "1  i set up my hd such that i have to type a pass...   \n",
       "2  im trying to use ubuntu on my macbook pro reti...   \n",
       "3  no suggestions? __eou__ links? __eou__ how can...   \n",
       "4  I just added a second usb printer but not sure...   \n",
       "\n",
       "                              Ground Truth Utterance  \\\n",
       "0                               nice thanks! __eou__   \n",
       "1  so you dont know, ok, anyone else? __eou__ you...   \n",
       "2                 just wondering how it runs __eou__   \n",
       "3  you cant load anything via usb or cd when luks...   \n",
       "4  i was setting it up under the printer configur...   \n",
       "\n",
       "                                        Distractor_0  \\\n",
       "0  wrong channel for it, but check efnet.org, uno...   \n",
       "1  nmap is nice, but it wasn't what I was looking...   \n",
       "2  yes, that's what I did, exported it to a \"id_d...   \n",
       "3    -p  sorry... __eou__  nmap -p22 __eou__ It d...   \n",
       "4  i'd say the most commonly venue would be via L...   \n",
       "\n",
       "                                        Distractor_1  \\\n",
       "0  every time the kernel changes, you will lose v...   \n",
       "1                                         ok __eou__   \n",
       "2  nothing - i am talking about the question of m...   \n",
       "3         i guess so i can't even launch it. __eou__   \n",
       "4  the old hardy man page, http://manpages.ubuntu...   \n",
       "\n",
       "                                        Distractor_2  \\\n",
       "0                                         ok __eou__   \n",
       "1   cdrom worked fine on windows. __eou__ i dont ...   \n",
       "2  that should fix the fonts being too large __eou__   \n",
       "3                                      noted __eou__   \n",
       "4                            i'll give a try __eou__   \n",
       "\n",
       "                                        Distractor_3  \\\n",
       "0  !nomodeset > acer __eou__ I'm assuming it is a...   \n",
       "1        ah yes, i have read return as rerun __eou__   \n",
       "2  okay, so hcitool echos back hci0 <mac address ...   \n",
       "3                        rxvt-unicode is one __eou__   \n",
       "4  by the way, the url you posted for davfs is fr...   \n",
       "\n",
       "                                        Distractor_4  \\\n",
       "0  http://www.ubuntu.com/project/about-ubuntu/der...   \n",
       "1                                        hm? __eou__   \n",
       "2  I get to the menu with options such as 'try ub...   \n",
       "3                          I tarred all of ~ __eou__   \n",
       "4  http://ubuntuforums.org/showthread.php?t=15498...   \n",
       "\n",
       "                                        Distractor_5  \\\n",
       "0  thx __eou__ unfortunately the program isn't in...   \n",
       "1  not the case, LTS is every other .04 release. ...   \n",
       "2  why do u need analyzer __eou__ it is a toy __e...   \n",
       "3                          I tarred all of ~ __eou__   \n",
       "4  So I load up putty gui, then what do I do? __e...   \n",
       "\n",
       "                                        Distractor_6  \\\n",
       "0  how can I check? By doing a recovery for testi...   \n",
       "1                                Pretty much __eou__   \n",
       "2  Cntrl-C may stop the command but it doesn't fi...   \n",
       "3  I don't really know if I can help, but I was c...   \n",
       "4   you should read error messages, it says 'are ...   \n",
       "\n",
       "                                        Distractor_7  \\\n",
       "0                        my humble apologies __eou__   \n",
       "1       I used the one I downloaded from AMD __eou__   \n",
       "2  if you're only going to run Ubuntu, just get a...   \n",
       "3              that works just fine, thanks! __eou__   \n",
       "4  waiting the college semester to close just to ...   \n",
       "\n",
       "                                        Distractor_8  \n",
       "0                           #ubuntu-offtopic __eou__  \n",
       "1  ffmpeg is part of the package , quixotedon , a...  \n",
       "2  the ones which are not picked up at the moment...  \n",
       "3                                  thank you __eou__  \n",
       "4  I was calling myself a jerk. All I know is tha...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anyone knows why my stock oneiric exports env var \\'USERNAME\\'?  I mean what is that used for?  I know of $USER but not $USERNAME .  My precise install doesn\\'t export USERNAME __eou__ __eot__ looks like it used to be exported by lightdm, but the line had the comment \"// FIXME: Is this required?\" so I guess it isn\\'t surprising it is gone __eou__ __eot__ thanks!  How the heck did you figure that out? __eou__ __eot__ https://bugs.launchpad.net/lightdm/+bug/864109/comments/3 __eou__ __eot__ '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the last statement isn't at all informative (from an NLP perspective)\n",
    "# So this is a tough training/test example\n",
    "# Success relies a lot on the context (previous dialog)\n",
    "df['Context'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nice thanks! __eou__'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Ground Truth Utterance'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i set up my hd such that i have to type a passphrase to access it at boot. how can i remove that passwrd, and just boot up normal. i did this at install, it works fine, just tired of having reboots where i need to be at terminal to type passwd in. help? __eou__ __eot__ backup your data, and re-install without encryption \"might\" be the easiest method __eou__ __eot__ '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And our bot is trying to mimic multiple IRC users\n",
    "# both the questioner and the answerer\n",
    "df['Context'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'so you dont know, ok, anyone else? __eou__ you are like, yah my mouse doesnt work, reinstall your os lolol what a joke __eou__'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So the antisocial sarcasm here would mistrain our bot\n",
    "df['Ground Truth Utterance'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'im trying to use ubuntu on my macbook pro retina __eou__ i read in the forums that ubuntu has a apple version now? __eou__ __eot__  not that ive ever heard of..  normal ubutnu should work on an intel based mac. there is the PPC version also. __eou__  you want total control? or what are you wanting exactly? __eou__ __eot__ '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Context'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'just wondering how it runs __eou__'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We only have to respond with a single utterance.\n",
    "# It can even be a question that isn't stated as a question\n",
    "df['Ground Truth Utterance'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_vectors = tfidf.fit_transform(['Hello World!', 'Goodbye cruel world.', 'hello Jane.'])\n",
    "sparse_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cruel': 0, 'goodbye': 1, 'hello': 2, 'jane': 3, 'world': 4}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cruel', 'goodbye', 'hello', 'jane', 'world']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cruel</th>\n",
       "      <th>goodbye</th>\n",
       "      <th>hello</th>\n",
       "      <th>jane</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.622766</td>\n",
       "      <td>0.622766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605349</td>\n",
       "      <td>0.795961</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cruel   goodbye     hello      jane     world\n",
       "0  0.000000  0.000000  0.707107  0.000000  0.707107\n",
       "1  0.622766  0.622766  0.000000  0.000000  0.473630\n",
       "2  0.000000  0.000000  0.605349  0.795961  0.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = pd.DataFrame(sparse_vectors.todense(), columns=tfidf.get_feature_names())\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.3, max_features=100000, min_df=8,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=8, max_df=.3, max_features=100000)\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.3, max_features=100000, min_df=8,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(pd.concat([df[df.columns[i]] for i in range(11)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anyone', 'knows', 'why', 'my', 'stock', 'oneiric', 'exports', 'env', 'var', 'username']\n",
      "12358\n"
     ]
    }
   ],
   "source": [
    "print(list(tfidf.vocabulary_)[:10])\n",
    "print(len(tfidf.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18920, 12358)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tfidf.transform(df.Context)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>0022</th>\n",
       "      <th>003</th>\n",
       "      <th>003a</th>\n",
       "      <th>01</th>\n",
       "      <th>011</th>\n",
       "      <th>...</th>\n",
       "      <th>zshwiki</th>\n",
       "      <th>zsnes</th>\n",
       "      <th>zsync</th>\n",
       "      <th>zvacet</th>\n",
       "      <th>zykes</th>\n",
       "      <th>zykotic9</th>\n",
       "      <th>zykotick9</th>\n",
       "      <th>zykotik9</th>\n",
       "      <th>ınstall</th>\n",
       "      <th>ıt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12358 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  0000  001  002  0022  003  003a   01  011 ...   zshwiki  zsnes  \\\n",
       "0  0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0 ...       0.0    0.0   \n",
       "1  0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0 ...       0.0    0.0   \n",
       "2  0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0 ...       0.0    0.0   \n",
       "3  0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0 ...       0.0    0.0   \n",
       "4  0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0 ...       0.0    0.0   \n",
       "\n",
       "   zsync  zvacet  zykes  zykotic9  zykotick9  zykotik9  ınstall   ıt  \n",
       "0    0.0     0.0    0.0       0.0        0.0       0.0      0.0  0.0  \n",
       "1    0.0     0.0    0.0       0.0        0.0       0.0      0.0  0.0  \n",
       "2    0.0     0.0    0.0       0.0        0.0       0.0      0.0  0.0  \n",
       "3    0.0     0.0    0.0       0.0        0.0       0.0      0.0  0.0  \n",
       "4    0.0     0.0    0.0       0.0        0.0       0.0      0.0  0.0  \n",
       "\n",
       "[5 rows x 12358 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(X.todense(), columns=tfidf.get_feature_names())\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tfidf.transform(df['Ground Truth Utterance']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statement(s='Hi', db=X.values, orig=df.Context.iloc):\n",
    "    q = tfidf.transform([s]).todense()[0]\n",
    "    best_similarity = -1\n",
    "    best_i = 0\n",
    "    for i, v in enumerate(db):\n",
    "        # print(i, q, v)\n",
    "        similarity = cosine_similarity(q, pd.np.array([v]))\n",
    "        if similarity > best_similarity:\n",
    "            best_similarity\n",
    "            best_i = i\n",
    "    return orig[best_i], best_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('what is the command used for fixing __eou__ help me .......what is the command used for fixing __eou__ __eot__ fixing what? __eou__ __eot__ ',\n",
       " 18919)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_statement('Hello Ubuntu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to fix partial updates __eou__'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Ground Truth Utterance'].iloc[get_statement(\"Ubuntu doesn't work on my Macbook Pro!\")[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply(s='Hi'):\n",
    "    return df['Ground Truth Utterance'].iloc[get_statement(s)[1]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nice thanks! __eou__'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reply('anyone knows why my stock oneiric exports env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_reply('aut the line had the comment \"// FIXME: Is this required?\" so I guess it isn\\'t surprising it is gone __eou__ __eot__ thanks!  How the heck did you figure that out? __eou__ __eot__ https://bugs.launchpad.net/lightdm/+bug/864109/comments/3 __eou__ __eot__ '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'so you dont know, ok, anyone else? __eou__ you are like, yah my mouse doesnt work, reinstall your os lolol what a joke __eou__'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reply('i set up my hd such that i have to type a pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=200)\n",
    "pca = pca.fit(tfidf.transform(df.Context).todense())\n",
    "X_100d = pca.transform(X)\n",
    "y_100d = pca.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statement_100d(s='Hi'):\n",
    "    q = pca.transform(tfidf.transform([s]).todense())[0]\n",
    "    similarity = 0\n",
    "    best_i = 0\n",
    "    for i, v in enumerate(X_100d):\n",
    "        # print(i, q.shape, v.shape)\n",
    "        sim = 2 - cosine_distances(pd.np.array([q]), pd.np.array([v]))\n",
    "        if sim > similarity:\n",
    "            similarity = sim\n",
    "            best_i = i\n",
    "    \n",
    "    return df.Context.iloc[best_i], best_i\n",
    "\n",
    "def get_reply_100d(s='Hi'):\n",
    "    return df['Ground Truth Utterance'].iloc[get_statement_100d(s)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anyone knows why my stock oneiric exports env var 'USERNAME'?  I mean what is that used for?  I know of $USER but not $USERNAME .  My precise install doesn't export USERNAME __eou__ __eot__ looks like it used to be exported by lightdm, but the line had the comment \"// FIXME: Is this required?\" so I guess it isn't surprising it is gone __eou__ __eot__ thanks!  How the heck did you figure that out? __eou__ __eot__ https://bugs.launchpad.net/lightdm/+bug/864109/comments/3 __eou__ __eot__ \n",
      "n\n",
      "ok, i just figured i'd ask here incase I was just retarded lol __eou__\n"
     ]
    }
   ],
   "source": [
    "print(get_statement_100d(df.Context[0])[0])\n",
    "print(get_reply_100d(df.Context[0])[0])\n",
    "print(get_reply_100d(\"I'm trying to use ubuntu on my macbook pro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I use cinnamon __eou__ But i don't know :P __eou__ __eot__ fair enough. I know Kazam has big issues in Gnome3 and cinnamon. __eou__ __eot__ \",\n",
       " 10644)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_statement_100d(\"me just installed another serial port copier but don't know\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('obi Its not working without USB stick. Without USB stick it asks to select a boot medium. With USB stick, it boots correctly. __eou__ obi Still the fdisk shows its not bootable. __eou__ __eot__ That display is irrelevant since 15 years :) __eou__ __eot__ ',\n",
       " 7989)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_statement_100d(\"I just added a second usb printer but not sure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and it still doesn't work? __eou__\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(get_reply_100d(\"Did you like the movie Avatar?\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
