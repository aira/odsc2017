{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'iteritems'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1f42eb16d431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msetup\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mDATA_PATH\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hobs/src/AgileMachineLearning/docs/nlp/notebooks/setup.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    685\u001b[0m POS_LABELS = {'0': '1', 'False': 'True', 'F': 'T', 'No': 'Yes', 'N': 'P',\n\u001b[1;32m    686\u001b[0m               'None': 'Positive', 'Neg': 'Pos', 'Negative': 'Positive', \"A\": \"B\"}\n\u001b[0;32m--> 687\u001b[0;31m \u001b[0mPOS_LABELS_INVERSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPOS_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0mPOS_LABELS_LOWER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPOS_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[0mPOS_LABELS_LOWER_INVERSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPOS_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'iteritems'"
     ]
    }
   ],
   "source": [
    "from setup import *\n",
    "import sys\n",
    "if DATA_PATH not in sys.path: sys.path.append(DATA_PATH)\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_rows', 6)\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('precision', 2)\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.657*\"Python\" + 0.378*\"RT\" + 0.243*\"to\" + 0.241*\"a\" + 0.222*\"in\" + 0.196*\"python\" + 0.178*\"the\" + 0.163*\"and\" + 0.146*\"for\" + 0.129*\"I\"')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi = LsiModel.load(os.path.join(DATA_PATH, 'lsi'))\n",
    "lsi4 = LsiModel.load(os.path.join(DATA_PATH, 'lsi4'))\n",
    "lsi.num_topics\n",
    "lsi.show_topics(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# favorites\n",
    "nums = pd.read_csv(os.path.join(DATA_PATH, 'numbers.csv.gz'))\n",
    "dates = pd.read_csv(os.path.join(DATA_PATH, 'datetimes.csv.gz'))\n",
    "\n",
    "vocab = Dictionary(df.txt.str.split())\n",
    "\n",
    "tfidf = TfidfModel(id2word=vocab, dictionary=vocab)\n",
    "\n",
    "lsi = LsiModel.load(os.path.join(DATA_PATH, 'lsi'))\n",
    "\n",
    "# Bags of words\n",
    "df = pd.DataFrame.from_csv(os.path.join(DATA_PATH, 'text.csv.gz'))\n",
    "bows = pd.Series(vocab.doc2bow(toks) for toks in df.txt.str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     23\n",
      "1     23\n",
      "2     22\n",
      "      ..\n",
      "97     5\n",
      "98     5\n",
      "99     3\n",
      "dtype: int64\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "     ..\n",
      "97    0\n",
      "98    0\n",
      "99    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "topics = lsi[tfidf[bows]]\n",
    "topics = pd.DataFrame((dict(top) for top in topics), index=df.index)\n",
    "print(topics.isnull().sum())\n",
    "topics.fillna(0, inplace=True)\n",
    "print(topics.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183067</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183068</th>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183069</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183070 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4     5     6     7     8     9     10  \\\n",
       "0       0.12  0.32 -0.10 -0.19  0.01 -0.02  0.25 -0.09  0.13  0.01  0.08   \n",
       "1       0.41 -0.36  0.09  0.04 -0.02 -0.00  0.11 -0.08  0.03 -0.01  0.16   \n",
       "2       0.03 -0.00  0.00  0.01 -0.02 -0.01  0.01 -0.01  0.01  0.00  0.03   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "183067  0.03  0.01 -0.02  0.01 -0.03 -0.01 -0.01 -0.07  0.05 -0.04  0.21   \n",
       "183068  0.41 -0.36  0.09  0.04 -0.02 -0.00  0.11 -0.08  0.03 -0.01  0.16   \n",
       "183069  0.00 -0.00  0.00 -0.00 -0.00 -0.00  0.00 -0.00  0.00 -0.00 -0.00   \n",
       "\n",
       "          11    12    13    14    15    16    17    18    19    20    21  \\\n",
       "0       0.04 -0.08  0.04  0.05 -0.04  0.00  0.02  0.03  0.15  0.11 -0.03   \n",
       "1       0.04 -0.11  0.01  0.04 -0.05 -0.05 -0.00 -0.06  0.02  0.05 -0.02   \n",
       "2       0.00 -0.03 -0.02  0.01 -0.00 -0.01  0.02 -0.03 -0.02 -0.00 -0.01   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "183067 -0.09  0.35  0.07 -0.11  0.06  0.03 -0.07 -0.00  0.02 -0.04 -0.04   \n",
       "183068  0.04 -0.11  0.01  0.04 -0.05 -0.05 -0.00 -0.06  0.02  0.05 -0.02   \n",
       "183069 -0.00  0.00 -0.00 -0.00  0.00 -0.00 -0.00  0.00  0.00 -0.00 -0.00   \n",
       "\n",
       "          22    23    24    25    26    27    28    29    30    31    32  \\\n",
       "0      -0.07  0.04  0.01 -0.02  0.01  0.00  0.02 -0.04 -0.02  0.01  0.02   \n",
       "1      -0.03  0.02 -0.05 -0.01  0.02 -0.01 -0.02 -0.00  0.02  0.04 -0.01   \n",
       "2       0.01  0.07 -0.01  0.00 -0.03 -0.01  0.07 -0.07 -0.02 -0.05  0.04   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "183067 -0.03  0.01 -0.00 -0.03  0.02  0.01  0.01 -0.00  0.00  0.01  0.00   \n",
       "183068 -0.03  0.02 -0.05 -0.01  0.02 -0.01 -0.02 -0.00  0.02  0.04 -0.01   \n",
       "183069 -0.00 -0.00 -0.00 -0.00  0.00  0.00  0.00 -0.00  0.00 -0.00 -0.00   \n",
       "\n",
       "          33    34    35    36    37    38    39    40    41    42    43  \\\n",
       "0       0.00  0.02  0.04  0.01  0.01 -0.04 -0.01  0.00  0.01  0.00 -0.02   \n",
       "1      -0.01 -0.02  0.03  0.01  0.01 -0.01 -0.00  0.00  0.03  0.03 -0.05   \n",
       "2       0.08 -0.01 -0.09 -0.02 -0.00 -0.06 -0.01  0.03  0.01  0.01 -0.20   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "183067  0.01  0.01  0.00 -0.01 -0.01 -0.00 -0.01  0.01 -0.01 -0.01 -0.01   \n",
       "183068 -0.01 -0.02  0.03  0.01  0.01 -0.01 -0.00  0.00  0.03  0.03 -0.05   \n",
       "183069  0.00  0.00  0.00 -0.00  0.00 -0.00 -0.00  0.00  0.00  0.00  0.00   \n",
       "\n",
       "          44    45    46    47    48    49    50    51    52    53    54  \\\n",
       "0       0.02 -0.01  0.01 -0.00  0.02  0.02  0.03 -0.00 -0.02 -0.00  0.01   \n",
       "1       0.02 -0.01  0.02 -0.02  0.02  0.01  0.01  0.00 -0.03  0.02 -0.01   \n",
       "2      -0.09  0.10  0.05 -0.24 -0.32 -0.18  0.01 -0.04 -0.05 -0.05 -0.07   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "183067 -0.00  0.01  0.01  0.00 -0.01  0.00 -0.00 -0.00  0.01 -0.01  0.02   \n",
       "183068  0.02 -0.01  0.02 -0.02  0.02  0.01  0.01  0.00 -0.03  0.02 -0.01   \n",
       "183069  0.00 -0.00 -0.00 -0.00 -0.01  0.00 -0.01 -0.00  0.00 -0.00  0.00   \n",
       "\n",
       "          55    56    57    58    59    60    61    62    63    64    65  \\\n",
       "0      -0.01 -0.03  0.02  0.01 -0.00  0.02  0.01  0.01 -0.01 -0.01  0.00   \n",
       "1      -0.05 -0.01  0.02  0.01  0.03  0.00  0.03 -0.06 -0.01 -0.03 -0.04   \n",
       "2       0.03 -0.02  0.01  0.09 -0.02 -0.11  0.02  0.15 -0.02 -0.02 -0.11   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "183067 -0.01  0.01  0.02  0.00 -0.01 -0.00  0.00 -0.00 -0.00 -0.01 -0.01   \n",
       "183068 -0.05 -0.01  0.02  0.01  0.03  0.00  0.03 -0.06 -0.01 -0.03 -0.04   \n",
       "183069 -0.00  0.00  0.00 -0.00 -0.01 -0.01  0.00 -0.01  0.00 -0.02 -0.00   \n",
       "\n",
       "          66    67    68    69    70    71    72    73    74    75    76  \\\n",
       "0       0.01 -0.00  0.01  0.02  0.00  0.01 -0.00 -0.01 -0.01  0.00  0.00   \n",
       "1       0.01 -0.02 -0.01 -0.01 -0.05  0.00 -0.05 -0.02 -0.00 -0.03 -0.06   \n",
       "2      -0.06  0.03 -0.06  0.01 -0.01 -0.01 -0.08  0.00 -0.01 -0.00 -0.05   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "183067  0.01  0.01 -0.01 -0.02 -0.00 -0.01 -0.00  0.01 -0.00  0.01 -0.00   \n",
       "183068  0.01 -0.02 -0.01 -0.01 -0.05  0.00 -0.05 -0.02 -0.00 -0.03 -0.06   \n",
       "183069  0.01  0.01  0.01 -0.00 -0.00 -0.01 -0.00  0.01  0.01  0.01  0.01   \n",
       "\n",
       "          77    78    79    80    81    82    83    84    85    86    87  \\\n",
       "0       0.00  0.00  0.02  0.00  0.01  0.00  0.00  0.00 -0.02  0.03  0.03   \n",
       "1      -0.01  0.03  0.04 -0.01  0.02 -0.02 -0.05  0.10  0.00  0.02 -0.05   \n",
       "2       0.03 -0.02 -0.02  0.00 -0.01  0.00 -0.04  0.02  0.01 -0.04 -0.04   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "183067  0.01  0.01  0.03  0.01  0.01  0.01  0.02  0.00  0.01  0.01 -0.01   \n",
       "183068 -0.01  0.03  0.04 -0.01  0.02 -0.02 -0.05  0.10  0.00  0.02 -0.05   \n",
       "183069  0.00 -0.01  0.01  0.01  0.01  0.00 -0.01  0.01 -0.02  0.00 -0.00   \n",
       "\n",
       "          88    89    90    91    92    93    94    95    96    97    98    99  \n",
       "0       0.01 -0.01  0.00 -0.00  0.02 -0.01  0.03 -0.01  0.02  0.00  0.01 -0.01  \n",
       "1       0.01 -0.02  0.03 -0.00  0.05  0.02  0.03 -0.02 -0.01  0.05  0.02 -0.01  \n",
       "2       0.01  0.06 -0.03 -0.04 -0.00  0.01 -0.04  0.01  0.01  0.04 -0.02  0.03  \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "183067  0.00 -0.01 -0.01 -0.01  0.01 -0.00  0.01  0.00  0.00  0.00 -0.01  0.01  \n",
       "183068  0.01 -0.02  0.03 -0.00  0.05  0.02  0.03 -0.02 -0.01  0.05  0.02 -0.01  \n",
       "183069 -0.00 -0.01  0.00  0.01 -0.01 -0.01  0.00  0.01  0.00  0.00 -0.00  0.00  \n",
       "\n",
       "[183070 rows x 100 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.copy().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I first ran this, my dataframes weren't \"aligned\".  \n",
    "So it's very important to check your datasets after every load.  \n",
    "The correspondence between dates and topics and numerical features is critical for training!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183070\n",
      "183070\n",
      "183070\n"
     ]
    }
   ],
   "source": [
    "print(len(dates))\n",
    "print(len(topics))\n",
    "print(len(nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(nums.index == dates.index) == len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(nums.index == topics.index) == len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc = LinearDiscriminantAnalysis()\n",
    "disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "category = (np.ceil(nums.favorite_count ** .13)).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disc = LinearDiscriminantAnalysis().fit(topics, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_favorites = disc.predict(topics)\n",
    "predicted_favorites[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2144"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predicted_favorites > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wow!  \n",
    "DiscriminantAnalysis is **VERY** discriminating!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33292"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(nums.favorite_count >= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But not in a good way.  \n",
    "10x more true favorites than predicted. \n",
    "Our unbalanced training set makes it easy for the judge to be tough.  \n",
    "Let's mellow our judge a bit...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>truth</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>147725</td>\n",
       "      <td>31117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>2053</td>\n",
       "      <td>2175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "truth       False  True \n",
       "predicted               \n",
       "False      147725  31117\n",
       "True         2053   2175"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "results['predicted'] = predicted_favorites\n",
    "results['truth'] = pd.Series(nums.favorite_count >= 1)\n",
    "conf = Confusion(results)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1326"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.predicted.corr(results.truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrettyDict([('tpr', 0.8260),\n",
       "            ('fpr', 0.4856),\n",
       "            ('tnr', 0.5144),\n",
       "            ('fnr', 0.1740),\n",
       "            ('plr', 1.7011),\n",
       "            ('nlr', 0.3382),\n",
       "            ('accuracy', 0.8188),\n",
       "            ('sensitivity', 0.8260),\n",
       "            ('specificity', 0.5144),\n",
       "            ('mcc', 0.1326),\n",
       "            ('chi_squared', 3217.3986)])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.stats_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High accuracy, but low MCC (correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance the training?  \n",
    "Get rid of some negatives?  \n",
    "**Accentuate the positive?** <-- give this a try yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60633\n",
      "66584\n"
     ]
    }
   ],
   "source": [
    "pos = np.array(nums.favorite_count >= 1)\n",
    "neg = ~pos\n",
    "portion_pos = float(sum(pos)) / len(nums)\n",
    "mask = ((np.random.binomial(1, portion_pos, size=len(nums)).astype(bool) & neg) | pos)\n",
    "disc = LinearDiscriminantAnalysis().fit(topics[mask], (nums.favorite_count[mask] >= 1))\n",
    "print(sum(mask))\n",
    "print(sum(pos) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>truth</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>79751</td>\n",
       "      <td>1355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>70027</td>\n",
       "      <td>31937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "truth      False  True \n",
       "predicted              \n",
       "False      79751   1355\n",
       "True       70027  31937"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "results['predicted'] = disc.predict(topics.values)\n",
    "results['truth'] = nums.favorite_count.values >= 1\n",
    "conf = Confusion(results)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3819"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.predicted.corr(results.truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrettyDict([('tpr', 0.9833),\n",
       "            ('fpr', 0.6868),\n",
       "            ('tnr', 0.3132),\n",
       "            ('fnr', 0.0167),\n",
       "            ('plr', 1.4317),\n",
       "            ('nlr', 0.0533),\n",
       "            ('accuracy', 0.6101),\n",
       "            ('sensitivity', 0.9833),\n",
       "            ('specificity', 0.3132),\n",
       "            ('mcc', 1.1766),\n",
       "            ('chi_squared', 253427.2867)])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.stats_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's add some more negative examples back in.  \n",
    "50x imbalance is defintiely misleading.  \n",
    "But 2-5x imbalance is probably OK.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114711\n",
      "66584\n"
     ]
    }
   ],
   "source": [
    "portion_neg = 3 * portion_pos\n",
    "mask = ((np.random.binomial(1, portion_neg, size=len(nums)).astype(bool) & neg) | pos)\n",
    "disc = LinearDiscriminantAnalysis().fit(topics[mask], nums.favorite_count[mask] >=1 )\n",
    "print(sum(mask))\n",
    "print(sum(pos) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>truth</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>133025</td>\n",
       "      <td>20356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>16753</td>\n",
       "      <td>12936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "truth       False  True \n",
       "predicted               \n",
       "False      133025  20356\n",
       "True        16753  12936"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "results['predicted'] = disc.predict(topics.values)\n",
    "results['truth'] = nums.favorite_count.values > 0\n",
    "conf = Confusion(results)\n",
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least the confusion matrix looks balanced now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2896"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.predicted.corr(results.truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should have known, imbalance doesn't help..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87655\n",
      "66584\n"
     ]
    }
   ],
   "source": [
    "portion_neg = 2 * portion_pos\n",
    "mask = ((np.random.binomial(1, portion_neg, size=len(nums)).astype(bool) & neg) | pos)\n",
    "disc = LinearDiscriminantAnalysis().fit(topics.values[mask], (nums.favorite_count.values > 0)[mask])\n",
    "print(sum(mask))\n",
    "print(sum(pos) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>truth</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>101101</td>\n",
       "      <td>6434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>48677</td>\n",
       "      <td>26858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "truth       False  True \n",
       "predicted               \n",
       "False      101101   6434\n",
       "True        48677  26858"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "results['predicted'] = disc.predict(topics.values)\n",
    "results['truth'] = nums.favorite_count.values > 0\n",
    "conf = Confusion(results)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3775"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.predicted.corr(results.truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like 38% correlation is all we can squeeze out of this simple model  \n",
    "Next up... adding number of followers and other features  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
